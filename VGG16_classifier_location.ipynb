{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNiX6zy31i7cWcOLoaYl0iY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoLo404Ko/VGG16_classifierLocation/blob/main/VGG16_classifier_location.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VtP5lglkbR-p"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras import utils as np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from keras.applications import vgg16\n",
        "from sklearn.model_selection import train_test_split\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = \"/content/sample_data/\"\n",
        "zip_dir = base_dir + \"zipImg\"\n",
        "zip_path = base_dir + \"zipImg/images.zip\"\n",
        "image_dir = base_dir + \"images\"\n",
        "dataset_dir = base_dir + \"dataset\"\n",
        "dataset_path = base_dir + 'dataset/dataset.xlsx'\n",
        "\n",
        "img_df = pd.read_excel(dataset_path)"
      ],
      "metadata": {
        "id": "og7qat1Grsqv"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(base_dir)\n",
        "\n",
        "if not os.path.exists(zip_dir):\n",
        "  os.mkdir(\"zipImg\")\n",
        "\n",
        "if not os.path.exists(image_dir):\n",
        "  os.mkdir(\"images\")\n",
        "\n",
        "if not os.path.exists(dataset_dir):\n",
        "  os.mkdir(\"dataset\")"
      ],
      "metadata": {
        "id": "Oeo_ZUHMMetc"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Разархивируем архив**"
      ],
      "metadata": {
        "id": "HvRDFljf2AJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def zip():\n",
        "  with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "      zip_ref.extractall(image_dir)"
      ],
      "metadata": {
        "id": "quCjWxu_2Evd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Загружаем изображения**"
      ],
      "metadata": {
        "id": "lQiXrTZSbatv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loadPathsImages():\n",
        "  names = img_df['Путь']\n",
        "  paths = []\n",
        "\n",
        "  for name in names:\n",
        "    full_path = image_dir + \"/\" + str(name)\n",
        "    paths.append(full_path)\n",
        "\n",
        "  paths = np.asarray(paths)\n",
        "  return paths"
      ],
      "metadata": {
        "id": "Ljj_iQ-NbbNa"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadImages(paths):\n",
        "  images = []\n",
        "\n",
        "  for path in paths:\n",
        "    #image = Image.open(path)\n",
        "    image = cv2.imread(path)\n",
        "\n",
        "    #print(image.shape)\n",
        "    #if (len(src.shape) != 3):\n",
        "      #image = cv2.cvtColor(src, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "\n",
        "    array = np.array(image)\n",
        "    images.append(array)\n",
        "\n",
        "  return images"
      ],
      "metadata": {
        "id": "vmqF-b_IbdL2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Уменьшаем размер до 224x224 и нормализуем**"
      ],
      "metadata": {
        "id": "5snYB6f6beUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resizeImages(images):\n",
        "  reImages = []\n",
        "\n",
        "  for img in images:\n",
        "    new_img = cv2.resize(img, (224, 224))\n",
        "    new_img = new_img / 255\n",
        "    reImages.append(new_img)\n",
        "  return reImages"
      ],
      "metadata": {
        "id": "ako4zmL5bgL6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Классы изображений**"
      ],
      "metadata": {
        "id": "-DkI4GEebimE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = {1:'Спальня', 2:'Частный дом', 3:'Промышленный район', 4:'Кухня', 5:'Гостинная', 6:'Море', 7:'Лес', 8:\n",
        " 'Дорога', 9:'Здание', 10:'Гора',11:'Равнина', 12:'Улица', 13:'Небоскреб', 14:'Рабочий кабинет', 15:'Магазин'}"
      ],
      "metadata": {
        "id": "Xb-AHYHnbjyh"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Загружаем метки и кодириуем по OHE**"
      ],
      "metadata": {
        "id": "KMmyT30-blRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loadLabels():\n",
        "  df = pd.read_excel(dir)\n",
        "\n",
        "  labels_df = df['Метка класса']\n",
        "  labels = []\n",
        "\n",
        "  for label in labels_df:\n",
        "    # Метки идут от 1, поэтому - 1\n",
        "    labels.append(label - 1)\n",
        "\n",
        "  labels = np.array(labels)\n",
        "  label_cat = keras.utils.to_categorical(labels)\n",
        "\n",
        "  return label_cat"
      ],
      "metadata": {
        "id": "P35lz2ZnbkUw"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Подготавливаем модель**"
      ],
      "metadata": {
        "id": "daxmyc99boyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepareModel():\n",
        "  vgg_model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(vgg_model)\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  # Разблокируем все последние слои для обучения\n",
        "  vgg_model.trainable = True\n",
        "  trainable = False\n",
        "  for layer in vgg_model.layers:\n",
        "      if layer.name == 'block5_conv1':\n",
        "          trainable = True\n",
        "      layer.trainable = trainable\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "z8IieKkKboTY"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Компилируем и обучаем модель**"
      ],
      "metadata": {
        "id": "i7C2NiBLbsqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainModel(model):\n",
        "  model = prepareModel()\n",
        "\n",
        "  early_stop = EarlyStopping(monitor='val_acc', min_delta=0.0001,\n",
        "                           patience=5, verbose=1, mode='auto')\n",
        "\n",
        "  # filepath = \"model.h5\"\n",
        "  # if os.path.exists(filepath):\n",
        "  #   checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "  # else:\n",
        "  #   checkpoint = ModelCheckpoint(model, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "\n",
        "  # callbacks = [early_stop, checkpoint]\n",
        "\n",
        "  model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics='accuracy')\n",
        "\n",
        "  # model.fit(X_train, y_train, epochs=5, batch_size=64, callbacks=callbacks)\n",
        "  model.fit(X_train, y_train, epochs=15, batch_size=512)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "QCdyLJh-bsUt"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Оцениваем модель**"
      ],
      "metadata": {
        "id": "-VXUdhdfeZI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateModel(model):\n",
        "  results = model.evaluate(X_test, y_test, batch_size=64)\n",
        "  print('test loss, test acc:', results)"
      ],
      "metadata": {
        "id": "Mo8YPNcjef4Q"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Прогноз модели**"
      ],
      "metadata": {
        "id": "7PuroP2qeqtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict():\n",
        "  image = Image.open('/content/sample_data/test.jpg')\n",
        "  image = np.array(image)\n",
        "  image = cv2.resize(image, (224, 224))\n",
        "  image = image / 255\n",
        "\n",
        "  print(X_train[0].shape)\n",
        "  print(image.shape)\n",
        "  image = np.expand_dims(image, axis=0)\n",
        "  pred = model.predict(image)\n",
        "  print(classes[np.argmax(pred)])"
      ],
      "metadata": {
        "id": "vJU0LqXveui1"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(os.listdir(zip_dir)) == 0:\n",
        "  zip()\n",
        "\n",
        "paths = loadPathsImages()\n",
        "images = loadImages(paths)\n",
        "\n",
        "\n",
        "\n",
        "X = np.asarray(resizeImages(images))\n",
        "y = loadLabels()\n",
        "\n",
        "del paths\n",
        "del images\n",
        "\n",
        "print(X.shape, y.shape)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "\n",
        "del X\n",
        "del y"
      ],
      "metadata": {
        "id": "_Yxv7maPbvqd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "866945a9-c136-4d29-f1c7-98c0112b2aaa"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/sample_data/zipImg/images.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-e586e3bfc37c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadPathsImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-ebfe6cc6e1d9>\u001b[0m in \u001b[0;36mzip\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m       \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/sample_data/zipImg/images.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = trainModel(model)"
      ],
      "metadata": {
        "id": "fTW8L0P8bxG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateModel(model)"
      ],
      "metadata": {
        "id": "Zu84uTVqnBQT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}